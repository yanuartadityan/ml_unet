{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image as Img\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "CURR_DIR = Path(\"__file__\").parent.resolve()\n",
    "TRAIN_IMG_DIR = CURR_DIR / \"../dataset/train_images/\"\n",
    "TRAIN_MASK_DIR = CURR_DIR / \"../dataset/train_masks/\"\n",
    "VAL_IMG_DIR = CURR_DIR / \"../dataset/val_images/\"\n",
    "VAL_MASK_DIR = CURR_DIR / \"../dataset/val_masks/\"\n",
    "\n",
    "class CarvanaSet(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple:\n",
    "        img_path = os.path.join(self.image_dir, self.images[index])\n",
    "        mask_path = os.path.join(\n",
    "            self.mask_dir, self.images[index].replace(\".jpg\", \"_mask.gif\")\n",
    "        )\n",
    "        # to augment using Albumentation, load into numpy array.\n",
    "        image = np.array(Img.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Img.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
    "        # normalize/convert white value from 255 to 1.0\n",
    "        mask[mask == 255] = 1.0\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        return (image, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform.\n",
    "simple_tx = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=240, height=240),\n",
    "        A.Rotate(limit=35, p=0.5),\n",
    "        A.Normalize(\n",
    "        mean=[0.0, 0.0, 0.0],\n",
    "        std=[1.0, 1.0, 1.0],\n",
    "        max_pixel_value=255.0,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = CarvanaSet(\n",
    "    image_dir=TRAIN_IMG_DIR,\n",
    "    mask_dir=TRAIN_MASK_DIR,\n",
    "    transform=simple_tx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PIL.\n",
    "training_images = os.listdir(TRAIN_IMG_DIR)\n",
    "training_masks = os.listdir(TRAIN_MASK_DIR)\n",
    "\n",
    "count = 0\n",
    "for img, mask in zip(training_images, training_masks):\n",
    "  img = Img.open(TRAIN_IMG_DIR / img)\n",
    "  img.show()\n",
    "  \n",
    "  if count == 2:\n",
    "    break\n",
    "\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
